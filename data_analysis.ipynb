{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd056edcafb40a48ac9331f4cd83ce0dae2cb35b505e0a45e3fd20930a2ac883a33",
   "display_name": "Python 3.8.8 64-bit ('sbaio': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "56edcafb40a48ac9331f4cd83ce0dae2cb35b505e0a45e3fd20930a2ac883a33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded training pairs  (13481429, 3)\n",
      "Loading views info ...\n",
      "Merged with train df\n",
      "Merged with test df\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from main import sample_customers, process_date_col, get_purchase_info\n",
    "\n",
    "# load training pairs\n",
    "df = pd.read_csv(\"data/labels_training.txt\")\n",
    "print(\"Loaded training pairs \", df.shape)\n",
    "\n",
    "## use customer data\n",
    "customers = pd.read_csv(\"data/customers.txt\")\n",
    "# update df\n",
    "df = pd.merge(df, customers, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "\n",
    "## use product data\n",
    "products = pd.read_csv(\"data/products.txt\")\n",
    "# replace dateOnSite with year, month, day ...\n",
    "dateOnSite = process_date_col(products['dateOnSite'])\n",
    "products = products.drop(columns=['dateOnSite'])\n",
    "products = pd.concat([products, dateOnSite], axis=1)\n",
    "# update df\n",
    "df = pd.merge(df, products, left_on=['productId'], right_on=['productId'], how='left')\n",
    "\n",
    "# add views\n",
    "print(\"Loading views info ...\")\n",
    "views = pd.read_csv(\"data/views.txt\")\n",
    "views = views.drop(columns=['imageZoom']) # discard imageZoom since all 0 but 1 value\n",
    "aggr_views = views.groupby(['customerId','productId']).sum() # aggregate the views\n",
    "# update df\n",
    "df = pd.merge(df, aggr_views, right_index=True, left_on=['customerId', 'productId'])\n",
    "print(\"Merged with train df\")\n",
    "\n",
    "## add purchase info\n",
    "customer_purchase_count, product_purchase_count = get_purchase_info()\n",
    "# add customer purchase info ?\n",
    "df = pd.merge(df, customer_purchase_count, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df.customerPurchaseCount.fillna(0, inplace=True)\n",
    "# add product purchase info ?\n",
    "df = pd.merge(df, product_purchase_count, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df.productPurchaseCount.fillna(0, inplace=True)\n",
    "\n",
    "# add other features\n",
    "# ...\n",
    "\n",
    "# load testing pairs\n",
    "df_test = pd.read_csv(\"data/labels_predict.txt\")\n",
    "df_test = pd.merge(df_test, customers, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df_test = pd.merge(df_test, products, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df_test = pd.merge(df_test, aggr_views, right_index=True, left_on=['customerId', 'productId'])\n",
    "print(\"Merged with test df\")\n",
    "\n",
    "# add customer purchase info ?\n",
    "df_test = pd.merge(df_test, customer_purchase_count, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df_test.customerPurchaseCount.fillna(0, inplace=True)\n",
    "# add product purchase info ?\n",
    "df_test = pd.merge(df_test, product_purchase_count, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df_test.productPurchaseCount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df.country.astype('category').cat.categories\n",
    "df.loc[:,[\"country\"]] = df.country.astype('category').cat.codes.astype(int)\n",
    "\n",
    "bool_d = {\"True\":1, \"False\":0, '1':1, '0':0, 1:1, 0:0}\n",
    "df.isFemale = df.isFemale.map(bool_d, na_action='ignore')\n",
    "df.isPremier = df.isPremier.map(bool_d, na_action='ignore')\n",
    "\n",
    "days = df.dateOnSite_dayname.astype('category').cat.categories\n",
    "df.loc[:,[\"dateOnSite_dayname\"]] = df.dateOnSite_dayname.astype('category').cat.codes.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country2id = dict([(v,k) for k,v in enumerate(countries)])\n",
    "df_test.country = df_test.country.map(country2id).fillna(len(countries)).astype(int)\n",
    "\n",
    "df_test.isFemale = df_test.isFemale.map(bool_d, na_action='ignore')\n",
    "df_test.isPremier = df_test.isPremier.map(bool_d, na_action='ignore')\n",
    "df_test.yearOfBirth = df_test.yearOfBirth\n",
    "\n",
    "day2id = dict([(v,k) for k,v in enumerate(days)])\n",
    "df_test.dateOnSite_dayname = df_test.dateOnSite_dayname.map(day2id).fillna(len(days)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "customerId                     0\n",
       "productId                      0\n",
       "purchase_probability     3345261\n",
       "isFemale                    4022\n",
       "country                        0\n",
       "yearOfBirth                 4022\n",
       "isPremier                   4022\n",
       "brand                          0\n",
       "price                          0\n",
       "productType                    0\n",
       "onSale                         0\n",
       "dateOnSite_year               81\n",
       "dateOnSite_month              81\n",
       "dateOnSite_day                81\n",
       "dateOnSite_dayname             0\n",
       "viewOnly                       0\n",
       "changeThumbnail                0\n",
       "viewCatwalk                    0\n",
       "view360                        0\n",
       "sizeGuide                      0\n",
       "customerPurchaseCount          0\n",
       "productPurchaseCount           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep held-out set\n",
    "held_out_frac = 0.1\n",
    "val_ind, train_ind = sample_customers(df, df['customerId'], frac=held_out_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.purchased\n",
    "customerId = df.customerId\n",
    "df.drop(columns=['purchased', 'customerId', 'productId'], inplace=True)\n",
    "df_test.drop(columns=['purchase_probability', 'customerId', 'productId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "isFemale                 float64\n",
       "country                    int64\n",
       "yearOfBirth              float64\n",
       "isPremier                float64\n",
       "brand                      int64\n",
       "price                    float64\n",
       "productType                int64\n",
       "onSale                      bool\n",
       "dateOnSite_year          float64\n",
       "dateOnSite_month         float64\n",
       "dateOnSite_day           float64\n",
       "dateOnSite_dayname         int64\n",
       "viewOnly                   int64\n",
       "changeThumbnail            int64\n",
       "viewCatwalk                int64\n",
       "view360                    int64\n",
       "sizeGuide                  int64\n",
       "customerPurchaseCount    float64\n",
       "productPurchaseCount     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "train_dset = lgb.Dataset(df.iloc[train_ind], label=label.iloc[train_ind])\n",
    "val_dset = lgb.Dataset(df.iloc[val_ind], label=label.iloc[val_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Number of positive: 245519, number of negative: 11887767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.738184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1355\n",
      "[LightGBM] [Info] Number of data points in the train set: 12133286, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020235 -> initscore=-3.879891\n",
      "[LightGBM] [Info] Start training from score -3.879891\n",
      "[1]\tvalid_0's auc: 0.799641\n",
      "[2]\tvalid_0's auc: 0.810663\n",
      "[3]\tvalid_0's auc: 0.817683\n",
      "[4]\tvalid_0's auc: 0.823077\n",
      "[5]\tvalid_0's auc: 0.827708\n",
      "[6]\tvalid_0's auc: 0.831495\n",
      "[7]\tvalid_0's auc: 0.833874\n",
      "[8]\tvalid_0's auc: 0.834995\n",
      "[9]\tvalid_0's auc: 0.837136\n",
      "[10]\tvalid_0's auc: 0.838569\n",
      "[11]\tvalid_0's auc: 0.839579\n",
      "[12]\tvalid_0's auc: 0.841018\n",
      "[13]\tvalid_0's auc: 0.841854\n",
      "[14]\tvalid_0's auc: 0.842843\n",
      "[15]\tvalid_0's auc: 0.843649\n",
      "[16]\tvalid_0's auc: 0.84414\n",
      "[17]\tvalid_0's auc: 0.845097\n",
      "[18]\tvalid_0's auc: 0.846067\n",
      "[19]\tvalid_0's auc: 0.846764\n",
      "[20]\tvalid_0's auc: 0.847378\n",
      "[21]\tvalid_0's auc: 0.848035\n",
      "[22]\tvalid_0's auc: 0.848929\n",
      "[23]\tvalid_0's auc: 0.849493\n",
      "[24]\tvalid_0's auc: 0.849948\n",
      "[25]\tvalid_0's auc: 0.850452\n",
      "[26]\tvalid_0's auc: 0.851399\n",
      "[27]\tvalid_0's auc: 0.851916\n",
      "[28]\tvalid_0's auc: 0.852462\n",
      "[29]\tvalid_0's auc: 0.85287\n",
      "[30]\tvalid_0's auc: 0.853204\n",
      "[31]\tvalid_0's auc: 0.853503\n",
      "[32]\tvalid_0's auc: 0.854176\n",
      "[33]\tvalid_0's auc: 0.85448\n",
      "[34]\tvalid_0's auc: 0.854711\n",
      "[35]\tvalid_0's auc: 0.855081\n",
      "[36]\tvalid_0's auc: 0.855422\n",
      "[37]\tvalid_0's auc: 0.855764\n",
      "[38]\tvalid_0's auc: 0.856079\n",
      "[39]\tvalid_0's auc: 0.856606\n",
      "[40]\tvalid_0's auc: 0.856792\n",
      "[41]\tvalid_0's auc: 0.857094\n",
      "[42]\tvalid_0's auc: 0.857287\n",
      "[43]\tvalid_0's auc: 0.8576\n",
      "[44]\tvalid_0's auc: 0.857804\n",
      "[45]\tvalid_0's auc: 0.858062\n",
      "[46]\tvalid_0's auc: 0.858246\n",
      "[47]\tvalid_0's auc: 0.858417\n",
      "[48]\tvalid_0's auc: 0.858573\n",
      "[49]\tvalid_0's auc: 0.858766\n",
      "[50]\tvalid_0's auc: 0.859027\n",
      "[51]\tvalid_0's auc: 0.859263\n",
      "[52]\tvalid_0's auc: 0.859348\n",
      "[53]\tvalid_0's auc: 0.859508\n",
      "[54]\tvalid_0's auc: 0.859762\n",
      "[55]\tvalid_0's auc: 0.859932\n",
      "[56]\tvalid_0's auc: 0.860099\n",
      "[57]\tvalid_0's auc: 0.860221\n",
      "[58]\tvalid_0's auc: 0.860373\n",
      "[59]\tvalid_0's auc: 0.860451\n",
      "[60]\tvalid_0's auc: 0.860585\n",
      "[61]\tvalid_0's auc: 0.860731\n",
      "[62]\tvalid_0's auc: 0.860869\n",
      "[63]\tvalid_0's auc: 0.860963\n",
      "[64]\tvalid_0's auc: 0.861042\n",
      "[65]\tvalid_0's auc: 0.861033\n",
      "[66]\tvalid_0's auc: 0.861164\n",
      "[67]\tvalid_0's auc: 0.86123\n",
      "[68]\tvalid_0's auc: 0.861322\n",
      "[69]\tvalid_0's auc: 0.8614\n",
      "[70]\tvalid_0's auc: 0.861523\n",
      "[71]\tvalid_0's auc: 0.861574\n",
      "[72]\tvalid_0's auc: 0.861717\n",
      "[73]\tvalid_0's auc: 0.861729\n",
      "[74]\tvalid_0's auc: 0.861731\n",
      "[75]\tvalid_0's auc: 0.861763\n",
      "[76]\tvalid_0's auc: 0.861868\n",
      "[77]\tvalid_0's auc: 0.861918\n",
      "[78]\tvalid_0's auc: 0.861991\n",
      "[79]\tvalid_0's auc: 0.861999\n",
      "[80]\tvalid_0's auc: 0.862101\n",
      "[81]\tvalid_0's auc: 0.862186\n",
      "[82]\tvalid_0's auc: 0.862262\n",
      "[83]\tvalid_0's auc: 0.86229\n",
      "[84]\tvalid_0's auc: 0.862364\n",
      "[85]\tvalid_0's auc: 0.86242\n",
      "[86]\tvalid_0's auc: 0.862471\n",
      "[87]\tvalid_0's auc: 0.862534\n",
      "[88]\tvalid_0's auc: 0.862562\n",
      "[89]\tvalid_0's auc: 0.862568\n",
      "[90]\tvalid_0's auc: 0.862638\n",
      "[91]\tvalid_0's auc: 0.862685\n",
      "[92]\tvalid_0's auc: 0.862701\n",
      "[93]\tvalid_0's auc: 0.862846\n",
      "[94]\tvalid_0's auc: 0.86288\n",
      "[95]\tvalid_0's auc: 0.862889\n",
      "[96]\tvalid_0's auc: 0.862923\n",
      "[97]\tvalid_0's auc: 0.862975\n",
      "[98]\tvalid_0's auc: 0.863001\n",
      "[99]\tvalid_0's auc: 0.863026\n",
      "[100]\tvalid_0's auc: 0.863088\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "bst = lgb.train(param, train_dset, num_round, valid_sets=[val_dset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = bst.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9920538613539628"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "test_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/labels_predict.txt\")\n",
    "df_test['purchase_probability'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         customerId  productId  purchase_probability\n",
       "0                 2    4601984              0.103446\n",
       "1                 2    5015355              0.014592\n",
       "2                 2    5022042              0.156199\n",
       "3                 2    5048287              0.040018\n",
       "4                 2    6016479              0.003866\n",
       "...             ...        ...                   ...\n",
       "3345256      399476    7188787              0.006904\n",
       "3345257      399476    7215288              0.005959\n",
       "3345258      399476    7258955              0.006968\n",
       "3345259      399476    7272924              0.005445\n",
       "3345260      399476    7411492              0.007497\n",
       "\n",
       "[3345261 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerId</th>\n      <th>productId</th>\n      <th>purchase_probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>4601984</td>\n      <td>0.103446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>5015355</td>\n      <td>0.014592</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5022042</td>\n      <td>0.156199</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5048287</td>\n      <td>0.040018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>6016479</td>\n      <td>0.003866</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3345256</th>\n      <td>399476</td>\n      <td>7188787</td>\n      <td>0.006904</td>\n    </tr>\n    <tr>\n      <th>3345257</th>\n      <td>399476</td>\n      <td>7215288</td>\n      <td>0.005959</td>\n    </tr>\n    <tr>\n      <th>3345258</th>\n      <td>399476</td>\n      <td>7258955</td>\n      <td>0.006968</td>\n    </tr>\n    <tr>\n      <th>3345259</th>\n      <td>399476</td>\n      <td>7272924</td>\n      <td>0.005445</td>\n    </tr>\n    <tr>\n      <th>3345260</th>\n      <td>399476</td>\n      <td>7411492</td>\n      <td>0.007497</td>\n    </tr>\n  </tbody>\n</table>\n<p>3345261 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_test.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}