{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd056edcafb40a48ac9331f4cd83ce0dae2cb35b505e0a45e3fd20930a2ac883a33",
   "display_name": "Python 3.8.8 64-bit ('sbaio': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "56edcafb40a48ac9331f4cd83ce0dae2cb35b505e0a45e3fd20930a2ac883a33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded training pairs  (13481429, 3)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from main import sample_customers,process_date_col\n",
    "\n",
    "# load training pairs\n",
    "df = pd.read_csv(\"data/labels_training.txt\")\n",
    "print(\"Loaded training pairs \", df.shape)\n",
    "\n",
    "## use customer data\n",
    "customers = pd.read_csv(\"data/customers.txt\")\n",
    "# update df\n",
    "df = pd.merge(df, customers, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "\n",
    "## use product data\n",
    "products = pd.read_csv(\"data/products.txt\")\n",
    "# replace dateOnSite with year, month, day ...\n",
    "dateOnSite = process_date_col(products['dateOnSite'])\n",
    "products = products.drop(columns=['dateOnSite'])\n",
    "products = pd.concat([products, dateOnSite], axis=1)\n",
    "# update df\n",
    "df = pd.merge(df, products, left_on=['productId'], right_on=['productId'], how='left')\n",
    "\n",
    "# add views\n",
    "print(\"Loading views info ...\")\n",
    "views = pd.read_csv(\"data/views.txt\")\n",
    "views = views.drop(columns=['imageZoom']) # discard imageZoom since all 0 but 1 value\n",
    "aggr_views = views.groupby(['customerId','productId']).sum() # aggregate the views\n",
    "# update df\n",
    "df = pd.merge(df, aggr_views, right_index=True, left_on=['customerId', 'productId'])\n",
    "print(\"Merged with train df\")\n",
    "# add other features\n",
    "# ...\n",
    "\n",
    "# load testing pairs\n",
    "df_test = pd.read_csv(\"data/labels_predict.txt\")\n",
    "df_test = pd.merge(df_test, customers, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df_test = pd.merge(df_test, products, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df_test = pd.merge(df_test, aggr_views, right_index=True, left_on=['customerId', 'productId'])\n",
    "print(\"Merged with test df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df.country.astype('category').cat.categories\n",
    "df.loc[:,[\"country\"]] = df.country.astype('category').cat.codes.astype(int)\n",
    "\n",
    "bool_d = {\"True\":1, \"False\":0, '1':1, '0':0, 1:1, 0:0}\n",
    "df.isFemale = df.isFemale.map(bool_d, na_action='ignore')\n",
    "df.isPremier = df.isPremier.map(bool_d, na_action='ignore')\n",
    "\n",
    "days = df.dateOnSite_dayname.astype('category').cat.categories\n",
    "df.loc[:,[\"dateOnSite_dayname\"]] = df.dateOnSite_dayname.astype('category').cat.codes.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country2id = dict([(v,k) for k,v in enumerate(countries)])\n",
    "df_test.country = df_test.country.map(country2id).fillna(len(countries)).astype(int)\n",
    "\n",
    "df_test.isFemale = df_test.isFemale.map(bool_d, na_action='ignore')\n",
    "df_test.isPremier = df_test.isPremier.map(bool_d, na_action='ignore')\n",
    "df_test.yearOfBirth = df_test.yearOfBirth\n",
    "\n",
    "day2id = dict([(v,k) for k,v in enumerate(days)])\n",
    "df_test.dateOnSite_dayname = df_test.dateOnSite_dayname.map(day2id).fillna(len(days)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "customerId                    0\n",
       "productId                     0\n",
       "purchase_probability    3345261\n",
       "isFemale                   4022\n",
       "country                       0\n",
       "yearOfBirth                4022\n",
       "isPremier                  4022\n",
       "brand                         0\n",
       "price                         0\n",
       "productType                   0\n",
       "onSale                        0\n",
       "dateOnSite_year              81\n",
       "dateOnSite_month             81\n",
       "dateOnSite_day               81\n",
       "dateOnSite_dayname            0\n",
       "viewOnly                      0\n",
       "changeThumbnail               0\n",
       "viewCatwalk                   0\n",
       "view360                       0\n",
       "sizeGuide                     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep held-out set\n",
    "held_out_frac = 0.1\n",
    "val_ind, train_ind = sample_customers(df, df['customerId'], frac=held_out_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.purchased\n",
    "customerId = df.customerId\n",
    "df.drop(columns=['purchased', 'customerId', 'productId'], inplace=True)\n",
    "df_test.drop(columns=['purchase_probability', 'customerId', 'productId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "isFemale              float64\n",
       "country                 int64\n",
       "yearOfBirth           float64\n",
       "isPremier             float64\n",
       "brand                   int64\n",
       "price                 float64\n",
       "productType             int64\n",
       "onSale                   bool\n",
       "dateOnSite_year       float64\n",
       "dateOnSite_month      float64\n",
       "dateOnSite_day        float64\n",
       "dateOnSite_dayname      int64\n",
       "viewOnly                int64\n",
       "changeThumbnail         int64\n",
       "viewCatwalk             int64\n",
       "view360                 int64\n",
       "sizeGuide               int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "train_dset = lgb.Dataset(df.iloc[train_ind], label=label.iloc[train_ind])\n",
    "val_dset = lgb.Dataset(df.iloc[val_ind], label=label.iloc[val_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Number of positive: 245519, number of negative: 11887767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.432571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 937\n",
      "[LightGBM] [Info] Number of data points in the train set: 12133286, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020235 -> initscore=-3.879891\n",
      "[LightGBM] [Info] Start training from score -3.879891\n",
      "[1]\tvalid_0's auc: 0.803118\n",
      "[2]\tvalid_0's auc: 0.808845\n",
      "[3]\tvalid_0's auc: 0.820178\n",
      "[4]\tvalid_0's auc: 0.822914\n",
      "[5]\tvalid_0's auc: 0.826834\n",
      "[6]\tvalid_0's auc: 0.829243\n",
      "[7]\tvalid_0's auc: 0.833165\n",
      "[8]\tvalid_0's auc: 0.834289\n",
      "[9]\tvalid_0's auc: 0.835711\n",
      "[10]\tvalid_0's auc: 0.83686\n",
      "[11]\tvalid_0's auc: 0.837524\n",
      "[12]\tvalid_0's auc: 0.838487\n",
      "[13]\tvalid_0's auc: 0.83927\n",
      "[14]\tvalid_0's auc: 0.840294\n",
      "[15]\tvalid_0's auc: 0.841176\n",
      "[16]\tvalid_0's auc: 0.842106\n",
      "[17]\tvalid_0's auc: 0.842854\n",
      "[18]\tvalid_0's auc: 0.843216\n",
      "[19]\tvalid_0's auc: 0.844137\n",
      "[20]\tvalid_0's auc: 0.844611\n",
      "[21]\tvalid_0's auc: 0.845223\n",
      "[22]\tvalid_0's auc: 0.845962\n",
      "[23]\tvalid_0's auc: 0.846539\n",
      "[24]\tvalid_0's auc: 0.84704\n",
      "[25]\tvalid_0's auc: 0.847909\n",
      "[26]\tvalid_0's auc: 0.848242\n",
      "[27]\tvalid_0's auc: 0.848782\n",
      "[28]\tvalid_0's auc: 0.849312\n",
      "[29]\tvalid_0's auc: 0.849932\n",
      "[30]\tvalid_0's auc: 0.850337\n",
      "[31]\tvalid_0's auc: 0.850845\n",
      "[32]\tvalid_0's auc: 0.851248\n",
      "[33]\tvalid_0's auc: 0.851789\n",
      "[34]\tvalid_0's auc: 0.852024\n",
      "[35]\tvalid_0's auc: 0.852355\n",
      "[36]\tvalid_0's auc: 0.852627\n",
      "[37]\tvalid_0's auc: 0.8529\n",
      "[38]\tvalid_0's auc: 0.853233\n",
      "[39]\tvalid_0's auc: 0.853628\n",
      "[40]\tvalid_0's auc: 0.853791\n",
      "[41]\tvalid_0's auc: 0.854035\n",
      "[42]\tvalid_0's auc: 0.854269\n",
      "[43]\tvalid_0's auc: 0.854383\n",
      "[44]\tvalid_0's auc: 0.854622\n",
      "[45]\tvalid_0's auc: 0.854756\n",
      "[46]\tvalid_0's auc: 0.854976\n",
      "[47]\tvalid_0's auc: 0.855242\n",
      "[48]\tvalid_0's auc: 0.85546\n",
      "[49]\tvalid_0's auc: 0.855598\n",
      "[50]\tvalid_0's auc: 0.855699\n",
      "[51]\tvalid_0's auc: 0.855892\n",
      "[52]\tvalid_0's auc: 0.85601\n",
      "[53]\tvalid_0's auc: 0.856177\n",
      "[54]\tvalid_0's auc: 0.856395\n",
      "[55]\tvalid_0's auc: 0.856541\n",
      "[56]\tvalid_0's auc: 0.85667\n",
      "[57]\tvalid_0's auc: 0.856746\n",
      "[58]\tvalid_0's auc: 0.856799\n",
      "[59]\tvalid_0's auc: 0.856916\n",
      "[60]\tvalid_0's auc: 0.857004\n",
      "[61]\tvalid_0's auc: 0.857126\n",
      "[62]\tvalid_0's auc: 0.857188\n",
      "[63]\tvalid_0's auc: 0.857308\n",
      "[64]\tvalid_0's auc: 0.857457\n",
      "[65]\tvalid_0's auc: 0.857603\n",
      "[66]\tvalid_0's auc: 0.857665\n",
      "[67]\tvalid_0's auc: 0.857738\n",
      "[68]\tvalid_0's auc: 0.857839\n",
      "[69]\tvalid_0's auc: 0.857913\n",
      "[70]\tvalid_0's auc: 0.85799\n",
      "[71]\tvalid_0's auc: 0.858085\n",
      "[72]\tvalid_0's auc: 0.858143\n",
      "[73]\tvalid_0's auc: 0.858202\n",
      "[74]\tvalid_0's auc: 0.858278\n",
      "[75]\tvalid_0's auc: 0.858347\n",
      "[76]\tvalid_0's auc: 0.858424\n",
      "[77]\tvalid_0's auc: 0.858428\n",
      "[78]\tvalid_0's auc: 0.858487\n",
      "[79]\tvalid_0's auc: 0.858542\n",
      "[80]\tvalid_0's auc: 0.85861\n",
      "[81]\tvalid_0's auc: 0.858689\n",
      "[82]\tvalid_0's auc: 0.858733\n",
      "[83]\tvalid_0's auc: 0.858819\n",
      "[84]\tvalid_0's auc: 0.858864\n",
      "[85]\tvalid_0's auc: 0.858904\n",
      "[86]\tvalid_0's auc: 0.858943\n",
      "[87]\tvalid_0's auc: 0.859007\n",
      "[88]\tvalid_0's auc: 0.85906\n",
      "[89]\tvalid_0's auc: 0.859118\n",
      "[90]\tvalid_0's auc: 0.859157\n",
      "[91]\tvalid_0's auc: 0.859187\n",
      "[92]\tvalid_0's auc: 0.859201\n",
      "[93]\tvalid_0's auc: 0.859254\n",
      "[94]\tvalid_0's auc: 0.859335\n",
      "[95]\tvalid_0's auc: 0.859349\n",
      "[96]\tvalid_0's auc: 0.859404\n",
      "[97]\tvalid_0's auc: 0.859468\n",
      "[98]\tvalid_0's auc: 0.859489\n",
      "[99]\tvalid_0's auc: 0.859466\n",
      "[100]\tvalid_0's auc: 0.859486\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "bst = lgb.train(param, train_dset, num_round, valid_sets=[val_dset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = bst.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9999986202112507"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/labels_predict.txt\")\n",
    "df_test['purchase_probability'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         customerId  productId  purchase_probability\n",
       "0                 2    4601984              0.103446\n",
       "1                 2    5015355              0.014592\n",
       "2                 2    5022042              0.156199\n",
       "3                 2    5048287              0.040018\n",
       "4                 2    6016479              0.003866\n",
       "...             ...        ...                   ...\n",
       "3345256      399476    7188787              0.006904\n",
       "3345257      399476    7215288              0.005959\n",
       "3345258      399476    7258955              0.006968\n",
       "3345259      399476    7272924              0.005445\n",
       "3345260      399476    7411492              0.007497\n",
       "\n",
       "[3345261 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerId</th>\n      <th>productId</th>\n      <th>purchase_probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>4601984</td>\n      <td>0.103446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>5015355</td>\n      <td>0.014592</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5022042</td>\n      <td>0.156199</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5048287</td>\n      <td>0.040018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>6016479</td>\n      <td>0.003866</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3345256</th>\n      <td>399476</td>\n      <td>7188787</td>\n      <td>0.006904</td>\n    </tr>\n    <tr>\n      <th>3345257</th>\n      <td>399476</td>\n      <td>7215288</td>\n      <td>0.005959</td>\n    </tr>\n    <tr>\n      <th>3345258</th>\n      <td>399476</td>\n      <td>7258955</td>\n      <td>0.006968</td>\n    </tr>\n    <tr>\n      <th>3345259</th>\n      <td>399476</td>\n      <td>7272924</td>\n      <td>0.005445</td>\n    </tr>\n    <tr>\n      <th>3345260</th>\n      <td>399476</td>\n      <td>7411492</td>\n      <td>0.007497</td>\n    </tr>\n  </tbody>\n</table>\n<p>3345261 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}