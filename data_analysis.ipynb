{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd056edcafb40a48ac9331f4cd83ce0dae2cb35b505e0a45e3fd20930a2ac883a33",
   "display_name": "Python 3.8.8 64-bit ('sbaio': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "56edcafb40a48ac9331f4cd83ce0dae2cb35b505e0a45e3fd20930a2ac883a33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded training pairs  (13481429, 3)\n",
      "Loading views info ...\n",
      "Merged with train df\n",
      "Merged with test df\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from main import sample_customers, process_date_col, get_purchase_info\n",
    "\n",
    "# load training pairs\n",
    "df = pd.read_csv(\"data/labels_training.txt\")\n",
    "print(\"Loaded training pairs \", df.shape)\n",
    "\n",
    "## use customer data\n",
    "customers = pd.read_csv(\"data/customers.txt\")\n",
    "# update df\n",
    "df = pd.merge(df, customers, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "\n",
    "## use product data\n",
    "products = pd.read_csv(\"data/products.txt\")\n",
    "# replace dateOnSite with year, month, day ...\n",
    "dateOnSite = process_date_col(products['dateOnSite'])\n",
    "products = products.drop(columns=['dateOnSite'])\n",
    "products = pd.concat([products, dateOnSite], axis=1)\n",
    "# update df\n",
    "df = pd.merge(df, products, left_on=['productId'], right_on=['productId'], how='left')\n",
    "\n",
    "# add views\n",
    "print(\"Loading views info ...\")\n",
    "views = pd.read_csv(\"data/views.txt\")\n",
    "views = views.drop(columns=['imageZoom']) # discard imageZoom since all 0 but 1 value\n",
    "aggr_views = views.groupby(['customerId','productId']).sum() # aggregate the views\n",
    "# update df\n",
    "df = pd.merge(df, aggr_views, right_index=True, left_on=['customerId', 'productId'])\n",
    "print(\"Merged with train df\")\n",
    "\n",
    "## add purchase info\n",
    "customer_purchase_count, product_purchase_count = get_purchase_info()\n",
    "# add customer purchase info ?\n",
    "df = pd.merge(df, customer_purchase_count, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df.customerPurchaseCount.fillna(0, inplace=True)\n",
    "# add product purchase info ?\n",
    "df = pd.merge(df, product_purchase_count, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df.productPurchaseCount.fillna(0, inplace=True)\n",
    "\n",
    "# add other features\n",
    "# ...\n",
    "\n",
    "# load testing pairs\n",
    "df_test = pd.read_csv(\"data/labels_predict.txt\")\n",
    "df_test = pd.merge(df_test, customers, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df_test = pd.merge(df_test, products, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df_test = pd.merge(df_test, aggr_views, right_index=True, left_on=['customerId', 'productId'])\n",
    "print(\"Merged with test df\")\n",
    "\n",
    "# add customer purchase info ?\n",
    "df_test = pd.merge(df_test, customer_purchase_count, left_on=['customerId'], right_on=['customerId'], how='left')\n",
    "df_test.customerPurchaseCount.fillna(0, inplace=True)\n",
    "# add product purchase info ?\n",
    "df_test = pd.merge(df_test, product_purchase_count, left_on=['productId'], right_on=['productId'], how='left')\n",
    "df_test.productPurchaseCount.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df.country.astype('category').cat.categories\n",
    "df.loc[:,[\"country\"]] = df.country.astype('category').cat.codes.astype(int)\n",
    "\n",
    "bool_d = {\"True\":1, \"False\":0, '1':1, '0':0, 1:1, 0:0}\n",
    "df.isFemale = df.isFemale.map(bool_d, na_action='ignore')\n",
    "df.isPremier = df.isPremier.map(bool_d, na_action='ignore')\n",
    "\n",
    "days = df.dateOnSite_dayname.astype('category').cat.categories\n",
    "df.loc[:,[\"dateOnSite_dayname\"]] = df.dateOnSite_dayname.astype('category').cat.codes.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country2id = dict([(v,k) for k,v in enumerate(countries)])\n",
    "df_test.country = df_test.country.map(country2id).fillna(len(countries)).astype(int)\n",
    "\n",
    "df_test.isFemale = df_test.isFemale.map(bool_d, na_action='ignore')\n",
    "df_test.isPremier = df_test.isPremier.map(bool_d, na_action='ignore')\n",
    "df_test.yearOfBirth = df_test.yearOfBirth\n",
    "\n",
    "day2id = dict([(v,k) for k,v in enumerate(days)])\n",
    "df_test.dateOnSite_dayname = df_test.dateOnSite_dayname.map(day2id).fillna(len(days)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "customerId                     0\n",
       "productId                      0\n",
       "purchase_probability     3345261\n",
       "isFemale                    4022\n",
       "country                        0\n",
       "yearOfBirth                 4022\n",
       "isPremier                   4022\n",
       "brand                          0\n",
       "price                          0\n",
       "productType                    0\n",
       "onSale                         0\n",
       "dateOnSite_year               81\n",
       "dateOnSite_month              81\n",
       "dateOnSite_day                81\n",
       "dateOnSite_dayname             0\n",
       "viewOnly                       0\n",
       "changeThumbnail                0\n",
       "viewCatwalk                    0\n",
       "view360                        0\n",
       "sizeGuide                      0\n",
       "customerPurchaseCount          0\n",
       "productPurchaseCount           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep held-out set\n",
    "held_out_frac = 0.1\n",
    "val_ind, train_ind = sample_customers(df, df['customerId'], frac=held_out_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.purchased\n",
    "customerId = df.customerId\n",
    "df.drop(columns=['purchased', 'customerId', 'productId'], inplace=True)\n",
    "df_test.drop(columns=['purchase_probability', 'customerId', 'productId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "isFemale                 float64\n",
       "country                    int64\n",
       "yearOfBirth              float64\n",
       "isPremier                float64\n",
       "brand                      int64\n",
       "price                    float64\n",
       "productType                int64\n",
       "onSale                      bool\n",
       "dateOnSite_year          float64\n",
       "dateOnSite_month         float64\n",
       "dateOnSite_day           float64\n",
       "dateOnSite_dayname         int64\n",
       "viewOnly                   int64\n",
       "changeThumbnail            int64\n",
       "viewCatwalk                int64\n",
       "view360                    int64\n",
       "sizeGuide                  int64\n",
       "customerPurchaseCount    float64\n",
       "productPurchaseCount     float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "train_dset = lgb.Dataset(df.iloc[train_ind], label=label.iloc[train_ind])\n",
    "val_dset = lgb.Dataset(df.iloc[val_ind], label=label.iloc[val_ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Number of positive: 245519, number of negative: 11887767\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.477118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1355\n",
      "[LightGBM] [Info] Number of data points in the train set: 12133286, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020235 -> initscore=-3.879891\n",
      "[LightGBM] [Info] Start training from score -3.879891\n",
      "[1]\tvalid_0's auc: 0.799641\n",
      "[2]\tvalid_0's auc: 0.810663\n",
      "[3]\tvalid_0's auc: 0.817683\n",
      "[4]\tvalid_0's auc: 0.823077\n",
      "[5]\tvalid_0's auc: 0.827708\n",
      "[6]\tvalid_0's auc: 0.831495\n",
      "[7]\tvalid_0's auc: 0.833874\n",
      "[8]\tvalid_0's auc: 0.834995\n",
      "[9]\tvalid_0's auc: 0.837136\n",
      "[10]\tvalid_0's auc: 0.838569\n"
     ]
    }
   ],
   "source": [
    "num_round = 10\n",
    "bst = lgb.train(param, train_dset, num_round, valid_sets=[val_dset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] Number of positive: 163260, number of negative: 7925597\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.440917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1355\n",
      "[LightGBM] [Info] Number of data points in the train set: 8088857, number of used features: 19\n",
      "[LightGBM] [Info] Number of positive: 162703, number of negative: 7926154\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.307390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1355\n",
      "[LightGBM] [Info] Number of data points in the train set: 8088857, number of used features: 19\n",
      "[LightGBM] [Info] Number of positive: 165075, number of negative: 7923783\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.423005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1355\n",
      "[LightGBM] [Info] Number of data points in the train set: 8088858, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020183 -> initscore=-3.882509\n",
      "[LightGBM] [Info] Start training from score -3.882509\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020114 -> initscore=-3.885997\n",
      "[LightGBM] [Info] Start training from score -3.885997\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020408 -> initscore=-3.871224\n",
      "[LightGBM] [Info] Start training from score -3.871224\n"
     ]
    }
   ],
   "source": [
    "# bst.best_score['valid_0']['auc']\n",
    "kfold = GroupKFold(n_splits=3)\n",
    "folds = kfold.split(X=df.iloc[train_ind], groups=customerId.iloc[train_ind])\n",
    "eval_hist = lgb.cv(param, train_dset, num_round, nfold=5, folds=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = bst.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9920538613539628"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "test_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/labels_predict.txt\")\n",
    "df_test['purchase_probability'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         customerId  productId  purchase_probability\n",
       "0                 2    4601984              0.103446\n",
       "1                 2    5015355              0.014592\n",
       "2                 2    5022042              0.156199\n",
       "3                 2    5048287              0.040018\n",
       "4                 2    6016479              0.003866\n",
       "...             ...        ...                   ...\n",
       "3345256      399476    7188787              0.006904\n",
       "3345257      399476    7215288              0.005959\n",
       "3345258      399476    7258955              0.006968\n",
       "3345259      399476    7272924              0.005445\n",
       "3345260      399476    7411492              0.007497\n",
       "\n",
       "[3345261 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customerId</th>\n      <th>productId</th>\n      <th>purchase_probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>4601984</td>\n      <td>0.103446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>5015355</td>\n      <td>0.014592</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5022042</td>\n      <td>0.156199</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>5048287</td>\n      <td>0.040018</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>6016479</td>\n      <td>0.003866</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3345256</th>\n      <td>399476</td>\n      <td>7188787</td>\n      <td>0.006904</td>\n    </tr>\n    <tr>\n      <th>3345257</th>\n      <td>399476</td>\n      <td>7215288</td>\n      <td>0.005959</td>\n    </tr>\n    <tr>\n      <th>3345258</th>\n      <td>399476</td>\n      <td>7258955</td>\n      <td>0.006968</td>\n    </tr>\n    <tr>\n      <th>3345259</th>\n      <td>399476</td>\n      <td>7272924</td>\n      <td>0.005445</td>\n    </tr>\n    <tr>\n      <th>3345260</th>\n      <td>399476</td>\n      <td>7411492</td>\n      <td>0.007497</td>\n    </tr>\n  </tbody>\n</table>\n<p>3345261 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_test.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}